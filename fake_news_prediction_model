# -*- coding: utf-8 -*-
"""Fake_News_Prediction_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CHm0WkYAk_OrVXlDJF0ZOZswpgeKn3T0

We are using LogisticRegression model.

# Roles of different libraries used by us:-
1. **Numpy** is useful for creating numpy arrays
2. **Pandas** is useful in creaing dataframs and storing the data in the dataframes
3. **re** is regular expression is used to search the words in a text
4. **nltk** is natural language toolkit .. corpus is text body...  stopwords means those words which doesn't add much value to text context like articles
5. **TfidVectorizer** converts text into feature Vectors (numbers)
6. **train_test_split** splits data into training and testing data
 
* Stemming is a function which takes a word and removes suffix and prefix and returns the root word of it.

About the Dataset:


1.   id: unique id for a news article
2.   title: the title of a news article
3.   autor: author of the news article
4.   text: the text of the article; could be incomplete
5.   label: a label that marks whether the news article is real or fake:


> 1: Fake news
0: real news
"""

import pandas as pd
import numpy as np
import re
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

"""Downloading all the stopwords

"""

import nltk
nltk.download('stopwords')

# printing the stopwords in english
print(stopwords.words('english'))

"""Data Preprocessing"""

# loading the dataset to a pandas DataFrame becaues pandas dataframe is more strucutures table
news_dataset = pd.read_csv('/content/train.csv',error_bad_lines=False, engine="python")

news_dataset.shape

#print first five rows of dataframe
news_dataset.head()

# counting the number of missing values in the dataset
news_dataset.isnull().sum()

#replacing the null values with empty string
news_dataset = news_dataset.fillna('')

#merging the author name and news title
news_dataset['content'] = news_dataset['author'] + ' ' + news_dataset['title']

print(news_dataset['content'])

#seperating the data & label
X = news_dataset.drop(columns='label', axis=1)  #for column 1 .. for row 0 
Y= news_dataset['label']

print(X)
print(Y)

"""Stemming
It is the process of reducing a word to a root word .. we will only convert these words to vecors(numbers)
example: actor, actress, acting ---> act 
"""

port_stem= PorterStemmer()

# def to create  a function for stemming
def stemming(content): 
   stemmed_content = re.sub("[^a-zA-Z]"," ", content)  #(Ë„ means exclusion of everything which is not alphabets and replacing it with null space)
   stemmed_content = stemmed_content.lower() #converting everything to lower case to make every letter equal
   stemmed_content = stemmed_content.split() #to split data set in a list
   stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')] #stemming
   stemmed_content = ' '.join(stemmed_content) #joining the data which was earlier splitted into list
   return stemmed_content

news_dataset['content'] = news_dataset['content'].apply(stemming)

print(news_dataset['content'])

#separating the data and label
X= news_dataset['content'].values
Y= news_dataset['label'].values

print(X)

print(Y)

Y.shape

#converting textual data to numerical data
vectorizer = TfidfVectorizer() #Tf stands for Term frequency .. idf stands for inverse document frequency ... It counts the number of times a word is repeated in a document
vectorizer.fit(X)

X= vectorizer.transform(X) #transform the values to numbers

print(X)

"""Splitting dataset into training and test data"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y, random_state =2) #label of X_train will be stored in Y_train .. stratify balances 0 and 1 ... random state is just to follow instructor.. it can be any integer value

"""Training the Model : LogisticRegression"""

model = LogisticRegression()

model.fit(X_train, Y_train)

"""Evaluation

Accuracy Score
"""

#accuracy score on the training data
X_train_prediction = model.predict(X_train) #X train prediction is predicted by our model and Y_train are original ... we will compare and get the accuracy of our model
training_data_accuracy = accuracy_score(X_train_prediction, Y_train)

print("Accuracy score of the training data : ", training_data_accuracy)

"""This model is preferred for binary classification"""

#accuracy score on testing data
X_test_prediction = model.predict(X_test)
testing_data_accuracy = accuracy_score(X_test_prediction, Y_test)

print("Accuracy score of the testing data : ", testing_data_accuracy)

"""Making a Predictive System"""

X_new = X_test[10]

prediction = model.predict(X_new)
print(prediction)

if (prediction[0]==0):
  print("The news is Real")
else:
  print("The news is Fake")

print(Y_test[10])